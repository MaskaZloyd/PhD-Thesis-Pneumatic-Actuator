
\section{Разработка нейросетевой суррогатной модели}\label{sec:ch4/sec4}
В рамках разработки нейросетевой суррогатной модели для многокритериальной
оптимизации алгоритмов управления электропневматическими приводами была предложена
архитектура, основанная на концепции остаточных блоков. Данный подход позволяет
эффективно обучать глубокие сети, преодолевая проблему затухающих градиентов.
Структура модели включает входной слой, принимающий вектор параметров настройки
алгоритма управления, последовательность остаточных блоков и выходной линейный слой,
предсказывающий значения критериев качества управления.

Для повышения обобщающей способности модели и снижения
риска переобучения применяется техника регуляризации.
Процесс разработки суррогатной модели включал в себя оптимизацию
гиперпараметров, таких как количество остаточных блоков, размерности
скрытых слоев и скорость обучения, с использованием байесовской оптимизации.
Данный подход позволил создать эффективную суррогатную модель, способную
точно аппроксимировать сложные нелинейные зависимости между параметрами
алгоритма управления и критериями качества электропневматического привода.

\subsection{Архитектура модели}\label{sec:ch4/sec4/subsec1}

В целях повышения эффективности и точности суррогатного моделирования была разработана нейронная сеть,
основанная на архитектуре с использованием остаточных блоков (Residual Blocks). Данная архитектура была
выбрана для обеспечения устойчивости обучения и возможности построения глубоких моделей, способных захватывать
сложные нелинейные зависимости между входными параметрами и выходными метриками системы.

\paragraph{Структура нейронной сети}\label{sec:ch4/sec4/subsec1/subsubsec1}

Разработанная нейронная сеть представляет собой глубокую многослойную перцептронную модель (Multilayer Perceptron, MLP) \cite*{goodfellow2016deep},
интегрированную с остаточными блоками для улучшения процесса обучения и повышения обобщающей способности модели.
Архитектура сети состоит из следующих компонентов:

\begin{enumerate}
    \item Входной слой: входной слой принимает вектор признаков $\mathbf{x} \in \mathbb{R}^n$,
          представляющий праметры инициализации системы. В данном случае -- это парметры,
          которые изменяются в процессе оптимизации алгоритма. Колличестов нейронов во входном
          слое соответствует размерности входного вектора $n$;

    \item Последовательность остаточных блоков: основная часть сети состоит из серии остаточных блоков,
          каждый из которых включает в себя два линейных слоя с последующей нормализацией батча \cite*{ioffe2015batch},
          функцией активации ReLU и Dropout для регуляризации. Остаточные блоки
          реализуются для обеспечения прямого прохождения градиентов и предотвращения
          проблем, связанных с обучением глубоких сетей, таких как исчезающие градиенты \cite*{he2016deep}.

    \item Финальный линейный слой: После последовательности остаточных блоков добавляется финальный линейный слой,
          количество нейронов которого соответствует размерности выходных метрик $m$.
          Этот слой отвечает за преобразование скрытых представлений в предсказания модели.
\end{enumerate}

Рассмотрим каждый элемент архитектуры подробнее.
Фундаментальным структурным элементом данной сети является остаточный блок,
математическое описание которого может быть представлено следующим образом:

\begin{equation}
    \mathbf{y} = F(\mathbf{x}, \{\mathbf{W}_i\}) + h(\mathbf{x}),
\end{equation}
где $F(\mathbf{x}, {\mathbf{W}_i})$ -- остаточную функцию;
$h(\mathbf{x})$ -- функцию тождественного отображения или линейного проецирования.

Детализируя структуру остаточного блока,
можно выразить $F(\mathbf{x}, {\mathbf{W}_i})$ как композицию нескольких операций:

\begin{equation}
    \begin{split}
        \mathbf{z}_1                    & = \sigma(\mathbf{W}_1\mathbf{x} + \mathbf{b}_1), \\
        \mathbf{z}_2                    & = D(\mathbf{z}_1, p),                            \\
        \mathbf{z}_3                    & = \mathbf{W}_2\mathbf{z}_2 + \mathbf{b}_2,       \\
        F(\mathbf{x}, \{\mathbf{W}_i\}) & = \mathbf{z}_3.
    \end{split}
\end{equation}
где $\mathbf{W}_1, \mathbf{W}_2 \in \mathbb{R}^{m \times n}$ -- весовые матрицы;
$\mathbf{b}_1, \mathbf{b}_2 \in \mathbb{R}^m$ -- векторы смещения;
$\sigma(\cdot)$ -- функция активации ReLU;
$D(\cdot, p)$ -- операция dropout с вероятностью $p$.

Функция активации ReLU определяется как \cite*{nair2010rectified}:
\begin{equation}
    \sigma(x) = \max(0, x).
\end{equation}

Механизм dropout представляет собой эффективный метод регуляризации \cite*{srivastava2014dropout},
широко применяемый в глубоких нейронных сетях для предотвращения переобучения
и повышения их обобщающей способности. В контексте рассматриваемой суррогатной
модели, dropout играет ключевую роль в обеспечении надежности
и устойчивости предсказаний.

Сущность метода dropout заключается в случайном "выключении" определенной
доли нейронов в процессе обучения. Математически этот процесс может быть описан
следующим образом:

\begin{equation}
    \tilde{\mathbf{z}} = \mathbf{m} \odot \mathbf{z},
\end{equation}
где $\mathbf{z} \in \mathbb{R}^n$ -- вектор активаций нейронов;
$\mathbf{m} \in {0, 1}^n$ -- бинарная маска dropout;
$\tilde{\mathbf{z}}$ -- результирующий вектор после применения dropout.

Элементы маски $\mathbf{m}$ генерируются независимо из распределения Бернулли с параметром $1-p$:

\begin{equation}
    m_i \sim \text{Bernoulli}(1-p), \quad i = 1, \ldots, n,
\end{equation}
где $p$ -- вероятность "выключения" нейрона, являющуюся одним из гиперпараметров модели.

Значение $1-p$, соответственно, определяет вероятность сохранения нейрона активным.

Применение dropout приводит к тому, что математическое
ожидание выходного значения каждого нейрона уменьшается в $1-p$ раз:

\begin{equation}
    \mathbb{E}[\tilde{z}_i] = (1-p)z_i.
\end{equation}

Для компенсации данного эффекта во время обучения, выход нейрона
корректируется путем масштабирования на $1/(1-p)$:

\begin{equation}
    \tilde{\mathbf{z}} = \frac{1}{1-p}\mathbf{m} \odot \mathbf{z}.
\end{equation}

Важно отметить, что на этапе инференса (применения обученной модели)
dropout не используется. Это эквивалентно использованию математического ожидания активаций:

\begin{equation}
    \mathbf{z}_{\text{test}} = \mathbb{E}[\tilde{\mathbf{z}}] = \mathbf{z}.
\end{equation}

Применение dropout в остаточном блоке суррогатной модели может быть выражено следующим образом:

\begin{equation}
    \begin{split}
        \mathbf{z}_1         & = \sigma(\mathbf{W}_1\mathbf{x} + \mathbf{b}_1)                                             \\
        \tilde{\mathbf{z}}_1 & = \frac{1}{1-p}\mathbf{m} \odot \mathbf{z}_1, \quad \mathbf{m}_i \sim \text{Bernoulli}(1-p) \\
        \mathbf{z}_2         & = \mathbf{W}_2\tilde{\mathbf{z}}_1 + \mathbf{b}_2
    \end{split}
\end{equation}
где $\sigma(\cdot)$ обозначает функцию активации;
$\mathbf{W}_1$ и $\mathbf{W}_2$ -- весовые матрицы;
$\mathbf{b}_1$ и $\mathbf{b}_2$ -- векторы смещения.

Остаточные блоки объединяются в последовательность, образуя глубокую модель, способную
захватывать сложные нелинейные зависимости между входными параметрами и выходными метриками
качества управления электропневматическим приводом.

\subsection{Процесс обучения}\label{sec:ch4/sec4/subsec2}

Процесс обучения модели направлен на минимизацию функции потерь,
описывающей отклонение прогнозов модели от истинных значений целевых критериев.
В данной работе обучаемая модель аппроксимирует зависимости между входными
параметрами и целевыми функциями в многокритериальной задаче оптимизации.
Цель обучения -- настройка параметров модели, обеспечивающих точное предсказание
значений критериев для новых наборов входных параметров.

Функция потерь формализуется как взвешенная среднеквадратичная ошибка (Weighted Mean Squared Error, WMSE):
\begin{equation}
\mathcal{L} = \frac{1}{n} \sum_{i=1}^n w_i \| \hat{y}_i - y_i \|^2,
\end{equation}
где $n$ -- число наблюдений;
$w_i$ -- весовой коэффициент для $i$-го наблюдения;
$\hat{y}_i$ -- прогноз модели;
$y_i$ -- истинное значение. 

Весовые коэффициенты $w_i$ определяются на основе принадлежности
данных фронту Парето, чтобы акцентировать обучение на наиболее значимых
для задачи многокритериальной оптимизации данных.

Для повышения устойчивости обучения входные параметры $X$ и целевые
значения $Y$ подвергались стандартизации. Это преобразование выполняется следующим образом:
\begin{equation}
x_i' = \frac{x_i - \mu_X}{\sigma_X}, \quad y_i' = \frac{y_i - \mu_Y}{\sigma_Y},
\end{equation}
где $\mu_X, \sigma_X$ -- среднее значение и стандартное отклонение для входных данных;
$\mu_Y, \sigma_Y$ -- аналогичные статистики для целевых критериев. 

Стандартизация устраняет влияние разницы масштабов входных и выходных переменных, что обеспечивает стабильность обучения.

Обучение выполнялось с использованием метода стохастического градиентного спуска
с адаптивной скоростью обучения (AdamW). Этот метод обновляет параметры модели $\theta$ на каждой итерации следующим образом:

\begin{equation}
\theta_{t+1} = \theta_t - \eta_t \frac{\nabla_\theta \mathcal{L}(\theta_t)}{\sqrt{v_t} + \epsilon} - \lambda \theta_t,
\end{equation}
где $\eta_t$ -- скорость обучения на $t$-й итерации;
$v_t$ -- экспоненциально взвешенное среднеквадратичное значение градиента;
$\epsilon$ -- малое значение для предотвращения деления на ноль;
$\lambda$ -- коэффициент регуляризации $L_2$, уменьшающий вероятность переобучения.

Для ускорения сходимости использовалась циклическая стратегия изменения
скорости обучения (Cyclic Learning Rate). Скорость обучения $\eta_t$ изменялась по следующему правилу:

\begin{equation}
\eta_t = \eta_{\min} + \frac{\eta_{\max} - \eta_{\min}}{2} \left(1 + \cos\left(\frac{\pi t}{T}\right)\right),
\end{equation}
где $\eta_{\min}$ и $\eta_{\max}$ -- минимальное и максимальное значения скорости обучения;
$T$ -- длина цикла. Данная стратегия позволяет модели избегать локальных минимумов функции потерь и ускоряет сходимость.

Для оценки качества модели использовался метод кросс-валидации,
при котором данные разбивались на $K$ равных частей. На каждом этапе
обучения $K-1$ частей данных использовались для обучения модели,
а оставшаяся часть -- для проверки качества. Средняя ошибка рассчитывалась следующим образом:

\begin{equation}
\mathcal{E}_{val} = \frac{1}{K} \sum_{k=1}^K \mathcal{L}_{val}^{(k)},
\end{equation}

где $\mathcal{L}_{val}^{(k)}$ -- ошибка функции потерь на $k$-й валидационной выборке.
Кросс-валидация позволяет объективно оценить способность модели обобщать
данные, то есть точно предсказывать критерии для новых входных параметров.

Гиперпараметры модели, такие как скорость обучения $\eta$, коэффициент
регуляризации $\lambda$ и длина цикла $T$, оптимизировались с использованием
Байесовской оптимизации. Задача формализуется следующим образом:

\begin{equation}
    \label{eq:hyperopt}
\min_{\eta, T, \lambda} \mathcal{E}_{val}(\eta, T, \lambda),
\end{equation}
где $\mathcal{E}_{val}$ -- средняя ошибка на валидационной выборке;
$\eta$ -- скорость обучения; $T$ -- длина цикла; $\lambda$ -- коэффициент
регуляризации. Этот подход эффективно исследует пространство гиперпараметров,
выбирая такие значения, которые минимизируют усреднённую ошибку.




\subsection{Оптимизация гиперпараметров}\label{sec:ch4/sec4/subsec3}

Оптимизация гиперпараметров модели, включая скорость обучения $\eta$, коэффициент регуляризации
$\lambda$ и длину цикла $T$, была выполнена с использованием Байесовской
оптимизации, которая формализуется задачей минимизации согласно уравнению \ref{eq:hyperopt}.

Метод Байесовской оптимизации позволяет минимизировать $\mathcal{E}_{val}$ путём последовательного
уточнения аппроксимации функции с использованием ограниченного числа её вызовов.

Основой метода является модель Гауссового процесса (GP),
которая описывает априорное распределение целевой функции:
\begin{equation}
f(\mathbf{x}) \sim \mathcal{GP}(m(\mathbf{x}), k(\mathbf{x}, \mathbf{x}')),
\end{equation}
где $\mathbf{x} = (\eta, \lambda, T)$ -- вектор гиперпараметров;
$m(\mathbf{x})$ -- априорное математическое ожидание (обычно полагается равным нулю);
$k(\mathbf{x}, \mathbf{x}')$ -- ковариационная функция, задающая корреляцию между точками.

Для ковариационной функции использовалось радиально-базисное ядро:
\begin{equation}
k(\mathbf{x}, \mathbf{x}') = \sigma^2 \exp\left(-\frac{\|\mathbf{x} - \mathbf{x}'\|^2}{2\ell^2}\right),
\end{equation}
где $\sigma^2$ -- дисперсия;
$\ell$ -- масштабный параметр, определяющий степень гладкости.

На каждой итерации метода аппроксимация обновляется с учётом новых
измерений $\mathcal{E}_{val}(\mathbf{x}_i)$, что позволяет уточнять
предсказания. Для выбора следующей точки $\mathbf{x}_{new}$, в которой будет
вычислена $\mathcal{E}_{val}$, максимизируется функция полезности $u(\mathbf{x})$,
такая как ожидаемое улучшение (Expected Improvement):
\begin{equation}
\text{EI}(\mathbf{x}) = \mathbb{E}[\max(0, f^* - f(\mathbf{x}))],
\end{equation}
где $f^*$ -- текущее наименьшее значение $\mathcal{E}_{val}$;
$f(\mathbf{x})$ -- случайная величина, заданная предсказанием
Гауссового процесса. Ожидаемое улучшение выражается аналитически:
\begin{equation}
\text{EI}(\mathbf{x}) = (f^* - \mu(\mathbf{x}))\Phi\left(\frac{f^* - \mu(\mathbf{x})}{\sigma(\mathbf{x})}\right) + \sigma(\mathbf{x})\phi\left(\frac{f^* - \mu(\mathbf{x})}{\sigma(\mathbf{x})}\right),
\end{equation}
где $\mu(\mathbf{x})$ и $\sigma(\mathbf{x})$ -- среднее и стандартное отклонение предсказания в
точке $\mathbf{x}$, задаваемые Гауссовым процессом;
$\Phi$ и $\phi$ -- кумулятивная функция распределения и плотность нормального распределения соответственно.

После выбора $\mathbf{x}_{new}$ и вычисления $\mathcal{E}_{val}(\mathbf{x}_{new})$ обновляется
апостериорное распределение Гауссового процесса, учитывающее все известные
точки $\{\mathbf{x}_i, \mathcal{E}_{val}(\mathbf{x}_i)\}$:
\begin{equation}
\mu(\mathbf{x}) = \mathbf{k}_*^\top \mathbf{K}^{-1} \mathbf{y}, \quad \sigma^2(\mathbf{x}) = k(\mathbf{x}, \mathbf{x}) - \mathbf{k}_*^\top \mathbf{K}^{-1} \mathbf{k}_*,
\end{equation}
где $\mathbf{K}$ -- ковариационная матрица всех известных точек;
$\mathbf{k}_*$ -- вектор ковариаций между $\mathbf{x}$ и известными точками;
$\mathbf{y}$ -- вектор значений $\mathcal{E}_{val}$.

Процесс продолжается до достижения критерия остановки -- минимизации дисперсии предсказания;
достижения заданного числа итераций. Байесовская оптимизация позволяет
минимизировать вычислительные затраты, обеспечивая нахождение
гиперпараметров $(\eta, \lambda, T)$, близких к глобальному минимуму.